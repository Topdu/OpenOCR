import argparse

import cv2
import numpy as np
import torch


def str2bool(v):
    return v.lower() in ('true', 'yes', 't', 'y', '1')


def str2int_tuple(v):
    return tuple([int(i.strip()) for i in v.split(',')])


def init_args():
    parser = argparse.ArgumentParser()
    # params for prediction engine
    parser.add_argument('--use_gpu', type=str2bool, default=False)

    # params for text detector
    parser.add_argument('--image_dir', type=str)
    parser.add_argument('--det_algorithm', type=str, default='DB')
    parser.add_argument('--det_model_dir', type=str)
    parser.add_argument('--det_limit_side_len', type=float, default=960)
    parser.add_argument('--det_limit_type', type=str, default='max')
    parser.add_argument('--det_box_type', type=str, default='quad')

    # DB parmas
    parser.add_argument('--det_db_thresh', type=float, default=0.3)
    parser.add_argument('--det_db_box_thresh', type=float, default=0.6)
    parser.add_argument('--det_db_unclip_ratio', type=float, default=1.5)
    parser.add_argument('--max_batch_size', type=int, default=10)
    parser.add_argument('--use_dilation', type=str2bool, default=False)
    parser.add_argument('--det_db_score_mode', type=str, default='fast')

    # params for text recognizer
    parser.add_argument('--rec_algorithm', type=str, default='SVTR_LCNet')
    parser.add_argument('--rec_model_dir', type=str)
    parser.add_argument('--rec_image_inverse', type=str2bool, default=True)
    parser.add_argument('--rec_image_shape', type=str, default='3, 48, 320')
    parser.add_argument('--rec_batch_num', type=int, default=6)
    parser.add_argument('--max_text_length', type=int, default=25)
    parser.add_argument('--vis_font_path',
                        type=str,
                        default='./doc/fonts/simfang.ttf')
    parser.add_argument('--drop_score', type=float, default=0.5)

    # params for text classifier
    parser.add_argument('--use_angle_cls', type=str2bool, default=False)
    parser.add_argument('--cls_model_dir', type=str)
    parser.add_argument('--cls_image_shape', type=str, default='3, 48, 192')
    parser.add_argument('--label_list', type=list, default=['0', '180'])
    parser.add_argument('--cls_batch_num', type=int, default=6)
    parser.add_argument('--cls_thresh', type=float, default=0.9)

    parser.add_argument('--warmup', type=str2bool, default=False)

    #
    parser.add_argument('--output', type=str, default='./inference_results')
    parser.add_argument('--save_crop_res', type=str2bool, default=False)
    parser.add_argument('--crop_res_save_dir', type=str, default='./output')

    # multi-process
    parser.add_argument('--use_mp', type=str2bool, default=False)
    parser.add_argument('--total_process_num', type=int, default=1)
    parser.add_argument('--process_id', type=int, default=0)

    parser.add_argument('--show_log', type=str2bool, default=True)
    return parser


def parse_args():
    parser = init_args()
    return parser.parse_args()


def get_rotate_crop_image(img, points):
    """
    img_height, img_width = img.shape[0:2]
    left = int(np.min(points[:, 0]))
    right = int(np.max(points[:, 0]))
    top = int(np.min(points[:, 1]))
    bottom = int(np.max(points[:, 1]))
    img_crop = img[top:bottom, left:right, :].copy()
    points[:, 0] = points[:, 0] - left
    points[:, 1] = points[:, 1] - top
    """
    assert len(points) == 4, 'shape of points must be 4*2'
    img_crop_width = int(
        max(np.linalg.norm(points[0] - points[1]),
            np.linalg.norm(points[2] - points[3])))
    img_crop_height = int(
        max(np.linalg.norm(points[0] - points[3]),
            np.linalg.norm(points[1] - points[2])))
    pts_std = np.float32([
        [0, 0],
        [img_crop_width, 0],
        [img_crop_width, img_crop_height],
        [0, img_crop_height],
    ])
    M = cv2.getPerspectiveTransform(points, pts_std)
    dst_img = cv2.warpPerspective(
        img,
        M,
        (img_crop_width, img_crop_height),
        borderMode=cv2.BORDER_REPLICATE,
        flags=cv2.INTER_CUBIC,
    )
    dst_img_height, dst_img_width = dst_img.shape[0:2]
    if dst_img_height * 1.0 / dst_img_width >= 1.5:
        dst_img = np.rot90(dst_img)
    return dst_img


def get_minarea_rect_crop(img, points):
    bounding_box = cv2.minAreaRect(np.array(points).astype(np.int32))
    points = sorted(list(cv2.boxPoints(bounding_box)), key=lambda x: x[0])

    index_a, index_b, index_c, index_d = 0, 1, 2, 3
    if points[1][1] > points[0][1]:
        index_a = 0
        index_d = 1
    else:
        index_a = 1
        index_d = 0
    if points[3][1] > points[2][1]:
        index_b = 2
        index_c = 3
    else:
        index_b = 3
        index_c = 2

    box = [points[index_a], points[index_b], points[index_c], points[index_d]]
    crop_img = get_rotate_crop_image(img, np.array(box))
    return crop_img


def check_gpu(use_gpu):
    if use_gpu and not torch.cuda.is_available():
        use_gpu = False
    return use_gpu


if __name__ == '__main__':
    pass
